{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import getCitations as gc\n",
    "gc.get_working_proxy()  # initialize the proxy\n",
    "from scholarly import scholarly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"EMG or electromyography or electromyogram\"\n",
    "\n",
    "search_query = scholarly.search_pubs(query, year_low=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query.total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m cite_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvenue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcited_by\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# use gc.get_citations to get the citations into dataframe in batches of 100 without using pandas append function\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     cite_table \u001b[38;5;241m=\u001b[39m \u001b[43mgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_citations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_low\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcite_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/dataset_citations/getCitations.py:101\u001b[0m, in \u001b[0;36mget_citations\u001b[0;34m(dataset, num_cites, year_low, year_high, start_index, citations)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ€¦\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvenue\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    100\u001b[0m     authors \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# save the author list as it will be expanded\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     filled_entry \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m authors\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# check if the \"journal\" or \"conference\" key is present, replace the venue with the name\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-sci/lib/python3.10/site-packages/scholarly/_scholarly.py:238\u001b[0m, in \u001b[0;36m_Scholarly.fill\u001b[0;34m(self, object, sections, sortby, publication_limit)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontainer_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPublication\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    237\u001b[0m     publication_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__nav)\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mpublication_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-sci/lib/python3.10/site-packages/scholarly/publication_parser.py:369\u001b[0m, in \u001b[0;36mPublicationParser.fill\u001b[0;34m(self, publication)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m publication[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET:\n\u001b[1;32m    368\u001b[0m     bibtex_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bibtex(publication[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl_scholarbib\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 369\u001b[0m     bibtex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbibtex_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     parser \u001b[38;5;241m=\u001b[39m bibtexparser\u001b[38;5;241m.\u001b[39mbparser\u001b[38;5;241m.\u001b[39mBibTexParser(common_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    371\u001b[0m     parsed_bib \u001b[38;5;241m=\u001b[39m remap_bib(bibtexparser\u001b[38;5;241m.\u001b[39mloads(bibtex,parser)\u001b[38;5;241m.\u001b[39mentries[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], _BIB_MAPPING, _BIB_DATATYPES)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-sci/lib/python3.10/site-packages/scholarly/_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "query = \"EMG or electromyography or electromyogram\"\n",
    "# get the citations in batches of 100 upto a maximum of 1000 citations published in 2020\n",
    "cite_table = pd.DataFrame(columns=['title', 'author', 'venue', 'year', 'url', 'cited_by', 'bib'])\n",
    "for i in range(0, 1000, 100):\n",
    "    # use gc.get_citations to get the citations into dataframe in batches of 100 without using pandas append function\n",
    "    cite_table = gc.get_citations(query, num_cites=100, year_low=2020, start_index=i, citations=cite_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the cited by column to integer and remove duplicates based on title\n",
    "cite_table['cited_by'] = cite_table['cited_by'].astype(int)\n",
    "cite_table.drop_duplicates(subset='title', inplace=True)\n",
    "# convert the year column to integer\n",
    "cite_table['year'] = cite_table['year'].astype(int)\n",
    "# sort the data based on the number of citations\n",
    "cite_table.sort_values(by='cited_by', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a TSV file\n",
    "cite_table.to_csv('emg_citations.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
