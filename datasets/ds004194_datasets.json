{
  "dataset_id": "ds004194",
  "date_retrieved": "2025-07-31T00:25:32.354487+00:00",
  "dataset_description": {
    "Name": "Visual ECoG dataset",
    "BIDSVersion": "1.9.2",
    "DatasetType": "raw",
    "License": "CC0",
    "Authors": [
      "Iris Groen",
      "Kenichi Yuasa",
      "Amber Brands",
      "Giovanni Piantoni",
      "Stephanie Montenegro",
      "Adeen Flinker",
      "Sasha Devore",
      "Orrin Devinsky",
      "Werner Doyle",
      "Patricia Dugan",
      "Daniel Friedman",
      "Nick Ramsey",
      "Natalia Petridou",
      "Jonathan Winawer"
    ],
    "Acknowledgements": "Other contributors to this dataset: Dora Hermes",
    "HowToAcknowledge": "Please cite Groen et al., (2022) when using the spatial pattern or temporal pattern task data. Please cite Yuasa et al., (2023) when using the prf task data. Please cite Brands et al., (2024) when using the six category localizer task data. (see ReferencesAndLinks)",
    "Funding": [
      "This work was funded by BRAIN Initiative, the National Institute of Mental Health of the National Institutes of Health under Award Number R01MH111417",
      "This work was supported in part through the NYU IT High Performance Computing resources, services, and staff expertise."
    ],
    "EthicsApprovals": [
      "The study was approved by the NYU Grossman School of Medicine Institutional Review Board and the ethical committee of the University Medical Center Utrecht, in accordance with the Declaration of Helsinki (2013)"
    ],
    "ReferencesAndLinks": [
      "Groen IIA, Piantoni G, Montenegro S, Flinker A, Devore S, Devinsky O, Doyle W, Dugan P, Friedman D, Ramsey N, Petridou N, Winawer JA. Temporal dynamics of neural responses in human visual cortex. The Journal of Neuroscience 42(40):7562-7580 https://doi.org/10.1523/JNEUROSCI.1812-21.2022",
      "Yuasa K, Groen IIA, Piantoni G, Montenegro S, Flinker A, Devore S, Devinsky O, Doyle W, Dugan P, Friedman D, Ramsey N, Petridou N, Winawer JA. Precise spatial tuning of visually driven alpha oscillations in human visual cortex. eLife12:RP90387 https://doi.org/10.7554/eLife.90387.1",
      "Brands AM, Devore S, Devinsky O, Doyle W, Flinker A, Friedman D, Dugan P, Winawer JA, Groen IIA (2024) Temporal dynamics of short-term neural adaptation in human visual cortex. https://doi.org/10.1101/2023.09.13.557378"
    ],
    "DatasetDOI": "doi:10.18112/openneuro.ds004194.v3.0.0"
  },
  "readme_content": "## Details related to access to the data\n\n- Contact person\n\nPlease contact Iris Groen (i.i.a.groen@uva.nl, https://orcid.org/0000-0002-5536-6128) for more information.\n\nPlease see the following papers for more details on the data collection and preprocessing: \n\nGroen IIA, Piantoni G, Montenegro S, Flinker A, Devore S, Devinsky O, Doyle W, Dugan P, Friedman D, Ramsey N, Petridou N, Winawer JA (2022) Temporal dynamics of neural responses in human visual cortex. The Journal of Neuroscience 42(40):7562-7580 (https://doi.org/10.1523/JNEUROSCI.1812-21.2022) \n\nYuasa K, Groen IIA, Piantoni G, Montenegro S, Flinker A, Devore S, Devinsky O, Doyle W, Dugan P, Friedman D, Ramsey N, Petridou N, Winawer JA. Precise Spatial Tuning of Visually Driven Alpha Oscillations in Human Visual Cortex. eLife12:RP90387 https://doi.org/10.7554/eLife.90387.1\n\nBrands AM, Devore S, Devinsky O, Doyle W, Flinker A, Friedman D, Dugan P, Winawer JA, Groen IIA (2024). Temporal dynamics of short-term neural adaptation in human visual cortex. https://doi.org/10.1101/2023.09.13.557378\n\n- Practical information to access the data\n\nProcessed data and model fits reported in Groen et al., (2022) are available in derivatives/Groenetal2022TemporalDynamicsECoG as matlab .mat files. Matlab code to load, process and plot these data (including 3D renderings of the participant's surface reconstructions and electrode positions) is available in https://github.com/WinawerLab/ECoG_utils and https://github.com/irisgroen/temporalECoG. These repositories have dependencies on other Matlab toolboxes (e.g., FieldTrip). See instructions on Github for relevant links and guidelines. \n\nProcessed data and model fits reported in Yuasa et al., (2023) are available in the Github repositories described in the paper.\n\nProcessed data and model fits reported in Brands et al., (2024) are available in derivatives/Brandsetal2024TemporalAdaptationECoGCategories as python .py files. Python code to process and analyze these data is available in the Github repositories described in the paper.\n\n## Overview\n\n- Project name\n\nVisual ECoG dataset\n\n- Years that the project ran\n\nData were collected between 2017-2020. Exact recording dates have been scrubbed for anonymization purposes.\n\n- Brief overview of the tasks in the experiment\n\nParticipants sub-p01 to sub-p11 viewed grayscale visual pattern stimuli that were varied in temporal or spatial properties. Participans sub-p11 to sub-p14 additionally saw color images of different image classes (faces, bodies, buildings, objects, scenes,  and scrambled) that were varied in temporal properties. See 'Independent Variables' below for more details.\n\nIn all tasks, participants were instructed to fixate a cross or point in the center of the screen and monitor it for a color change, i.e. to perform a stimulus-orthogonal task (see the task-specific _events.json files, e.g., task-prf_events.json, for further details).\n\n- Description of the contents of the dataset\n\nThe data consists of cortical iEEG recordings in 14 epilepsy patients in response to visual stimulation. Patients were implanted with standard clinical surface (grid) and depth electrodes. Two patients were additionally implanted with a high-density research grid. In addition to the ieeg recordings, pre-implantation MRI T1 scans are provided for the purpose of localizing electrodes. Participants performed a varying number of tasks and runs. \n\n- Independent variables\n\nThe data are divided in 6 different sets of stimulus types or events:\n\n1. prf: grayscale, oriented bar stimuli consisting of curved, band-pass filtered lines that were swept across the screen (up to (~16 degree of visual angle) in a fixed order for the purpose of estimating spatial population receptive fields (pRFs).\n2. spatialpattern: grayscale, centrally presented pattern stimuli (~16 degree of visual angle diameter) consisting of curved, band-pass filtered lines that were systematically varied in level of contrast and density, as well as various oriented grating stimuli.\n3. temporalpattern: grayscale, centrally presented pattern stimuli (~16 degree of visual angle diameter) consisting of curved, band-pass filtered lines that were systematically varied in temporal duration and interval.\n4. soc: combination of the spatialpattern and temporalpattern stimuli. \n5. sixcatloctemporal: color images of six stimulus classes: faces, bodies (hands/feet only), buildings, objects, scenes and scrambled, systematically varied in temporal duration and interval, whereby interval stimuli consisted of direct repeats of the identical image. \n6. sixcatlocisidiff/sixcatlocdiffisi: color images of six stimulus classes: faces, bodies (hands/feet only), buildings, objects, scenes and scrambled, systematically varied in temporal duration and interval, whereby the first interval stimulus was followed by images from either the same or a different category (but not the identical image).  \n\nParticipant-, task- and run-specific stimuli are provided in the /stimuli folder as matlab .mat files. \n\n- Dependent variables\n\nThe main BIDS folder contains the raw voltage data, split up in individual task runs. \nThe /derivatives/ECoGCAR folder contains common-average-referenced version of the data. \nThe /derivatives/ECoGBroadband folder contains time-varying broadband responses estimated by band-pass filtering the common-average-referenced voltage data and taking the average power envelope. \nThe /derivatives/ECoGPreprocessed folder contains epoched trials used in Brands et al., (2024).\nThe /derivatives/freesurfer folder contains surface reconstructions of each participant's T1, along with retinotopic atlas files. \nThe /derivatives/Groen2022TemporalDynamicsECoG contains preprocessed data and model fits that can be used to reproduce the results reported in Groen et al., (2022).\nThe /derivatives/Brands2024TemporalAdaptationECoG contains preprocessed data and model fits that can be used to reproduce the results reported in Brands et al., (2024).\n\n\n- Quality assessment of the data\n\nData quality and number of trials per subjects varies considerably across patients, for various reasons.\n\nFirst, for each recording session, attempts were made to optimize the environment for running visual experiments; e.g. room illumination was stabilized as much as possible by closing blinds when available, the visual display was calibrated (for most patients), and interference from medical staff or visitors was minimized. However, it was not possible to equate this with great precision across patients and sessions/runs. \n\nSecond, implantations were determined based on clinical needs and electrode locations therefore vary across participants. The strength and robustness of the neural responses varies greatly with the electrode location (e.g. early vs higher-level visual cortex), as well as with uncontrolled factors such as how well the electrode made contact with the cortex and whether it was primarily situated on grey matter (surface/grid electrodes) or could be located in white matter (some depth electrodes). Electrodes that were marked as containing epileptic activity by clinicians, or that did not have good signal based on visual inspection of the raw data, are marked as 'bad' in the channels.tsv files. \n\nThird, patients varied greatly in their cognitive abilities and mental/medical state, which affected their ability to follow task instructions, e.g. to remain alert and fixation. Some patients were able to perform repeated runs of multiple tasks across multiple sessions, while others only managed to do a few runs. \n\nAll patients included in this dataset have sufficiently good responses in some electrodes/tasks as judged by Groen et al., (2022) and Brands et al., (2024). However, when using this dataset to address further research questions, it is advisable to set stringent requirements on electrode and trial selection. See Groen et al., (2022) and associated code repository for an example preprocessing pipeline that selected for robust visual responses to temporally- and contrast-varying stimuli.\n\n## Methods\n\n- Subjects\n\nAll participants were intractable epilepsy patients who were undergoing ECoG for the purpose of monitoring seizures. Participants were included if their implantation covered parts of visual cortex and if they consented to participate in research.\n\n- Apparatus\n\nData were collected in a clinical setting, i.e. at bedside in the patient's hospital room. Information about iEEG recording apparatus is provided the meta data for each patient. Information about the visual stimulation equipment and behavioral response recordings are provided in Groen et al., (2022), Yuasa et al., (2023) and Brands et al., (2024). \n\n- Experimental location\n\nData were collected at NYU University Langone Hospital (New York, USA) or at University Medical Center Utrecht (The Netherlands).\n\n- Missing data\n\nStimulus files are missing for a few runs of sub-02. These are marked as N/A in the associated event files.\n\n## Notes\n\nFurther participant-specific notes:\n\n- For sub-03 and sub-04 the spatial pattern and temporal pattern stimuli are combined in the soc task runs, for the remaining participants these are split across the spatialpattern and temporalpattern task runs.\n\n- The pRF task from sub-04 has different prf parameters (bar duration and gap). \n\n- The first two runs of the pRF task from sub-05 are not of good quality (participant repeatedly broke fixation). In addition, the triggers in all pRF runs from sub-05 are not correct due to a stimulus coding problem and will need to be re-interpolated if one wishes to use these data.\n\n- Participants sub-10 and sub-11 have high density grids in addition to clinical grids.\n\n- Note that all stimuli and stimulus parameters can be found in the participant-specific stimulus *.mat files. \n",
  "github_info": {
    "repository_url": "https://github.com/OpenNeuroDatasets/ds004194",
    "exists": true,
    "description": "OpenNeuro dataset - Visual ECoG dataset",
    "created_at": "2022-07-06T15:43:09+00:00",
    "updated_at": "2025-04-01T10:26:07+00:00",
    "default_branch": "main"
  },
  "retrieval_status": {
    "dataset_description": "not_found",
    "readme": "not_found",
    "repository": "success"
  }
}