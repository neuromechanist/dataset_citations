{
  "dataset_id": "ds004212",
  "date_retrieved": "2025-07-31T00:14:03.284607+00:00",
  "dataset_description": {
    "Name": "THINGS-MEG",
    "BIDSVersion": "1.21",
    "License": "CC0",
    "Authors": [
      "Martin N. Hebart",
      "Oliver Contier",
      "Lina Teichmann",
      "Adam H. Rockter",
      "Charles Zheng",
      "Alexis Kidder",
      "Anna Corriveau",
      "Maryam Vaziri-Pashkam",
      "Chris I. Baker"
    ],
    "HowToAcknowledge": "Please cite this paper: https://doi.org/10.7554/eLife.82580",
    "EthicsApprovals": [
      "NIH Institutional Review Board as part of the study protocol 93-M-0170 (NCT00001360)"
    ],
    "ReferencesAndLinks": [
      "fMRI & MEG Paper: Hebart, M. N., Contier, O., Teichmann, L., Rockter, A. H., Zheng, C. Y., Kidder, A., ... & Baker, C. I. (2023). THINGS-data, a multimodal collection of large-scale datasets for investigating object representations in human brain and behavior. Elife, 12, e82580.",
      "Code: https://github.com/ViCCo-Group/THINGS-data",
      "Image Database Paper: Hebart M. N., Dickter A. H., Kidder A., Kwok W.  Y., Corriveau A., et al. (2019) THINGS: A database of 1,854 object concepts and more than 26,000 naturalistic object images. PLOS ONE 14(10): e0223792. https://doi.org/10.1371/journal.pone.0223792",
      "Image Database: https://osf.io/jum2f/",
      "Behavioral Triplet Odd-one-out dataset: https://osf.io/f5rn6/",
      "THINGS-fMRI dataset: doi:10.18112/openneuro.ds004192.v1.0.7",
      "THINGS-EEG1 dataset: doi:10.18112/openneuro.ds003825.v1.2.0"
    ],
    "DatasetDOI": "doi:10.18112/openneuro.ds004212.v2.0.1"
  },
  "readme_content": "# THINGS-MEG\n\nUnderstanding object representations visual and semantic processing of objects requires a broad, comprehensive sampling of the objects in our visual world\nwith dense measurements of brain activity and behavior. This densely sampled fMRI dataset is part of THINGS-data, a multimodal collection\nof large-scale datasets comprising functional MRI, magnetoencephalographic recordings, and 4.70 million behavioral judgments in response to thousands of photographic images\nfor up to 1,854 object concepts. THINGS-data is unique in its breadth of richly-annotated objects, allowing for testing countless novel hypotheses at scale while assessing\nthe reproducibility of previous findings. The multimodal data allows for studying both the temporal and spatial dynamics of object representations and their relationship\nto behavior and additionally provides the means for combining these datasets for novel insights into object processing. THINGS-data constitutes the core release of\nthe [THINGS initiative](https://things-initiative.org) for bridging the gap between disciplines and the advancement of cognitive neuroscience.\n\n# Dataset overview\n\nWe collected extensively sampled object representations using magnetoencephalography (MEG). To this end, we drew on the THINGS database [(Hebart et al., 2019)](https://doi.org/10.1371/journal.pone.0223792),\na richly-annotated database of 1,854 object concepts representative of the American English language which contains 26,107 manually-curated naturalistic object images.\n\nDuring the fMRI experiment, participants were shown a representative subset of THINGS images, spread across 12 separate sessions (N=4, 22,448 unique images of 1,854 objects).\nImages were shown in fast succession (1.5Â±0.2s), and participants were instructed to maintain central fixation. To ensure engagement, participants performed an oddball detection task\nresponding to occasional artificially-generated images. A subset of images (n=200) were shown repeatedly in each session.\n\nBeyond the core functional imaging data in response to THINGS images, we acquired T1-weighted MRI scans to allow for cortical source localization.\nEye movements were monitored in the MEG to ensure participants maintained central fixation.\n",
  "github_info": {
    "repository_url": "https://github.com/OpenNeuroDatasets/ds004212",
    "exists": true,
    "description": "OpenNeuro dataset - THINGS-MEG",
    "created_at": "2023-01-05T14:14:21+00:00",
    "updated_at": "2025-07-14T10:12:51+00:00",
    "default_branch": "main"
  },
  "retrieval_status": {
    "dataset_description": "not_found",
    "readme": "not_found",
    "repository": "success"
  }
}